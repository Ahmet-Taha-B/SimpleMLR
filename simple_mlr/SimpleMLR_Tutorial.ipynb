{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimpleMLR Tutorial: Machine Learning Made Simple\n",
    "\n",
    "Welcome to SimpleMLR! This tutorial will show you how to use all three boosting algorithms (XGBoost, LightGBM, and sklearn GBM) with a simple, consistent interface.\n",
    "\n",
    "## What You'll Learn:\n",
    "- üöÄ One-line model training and evaluation\n",
    "- üéØ Automatic hyperparameter optimization with smart strategies\n",
    "- üìä Beautiful visualizations to understand your model's performance\n",
    "- ‚ö° GPU acceleration when available\n",
    "- üîß How to compare different algorithms easily\n",
    "\n",
    "We'll use the **Tips dataset** from Seaborn to predict tip amounts based on bill features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better plots\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üìö Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore the Data\n",
    "\n",
    "We'll use the famous **Tips dataset** - it contains information about restaurant bills and tips. Our goal is to predict the tip amount based on various features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tips dataset from seaborn\n",
    "tips = sns.load_dataset('tips')\n",
    "\n",
    "print(\"üçΩÔ∏è Tips Dataset Overview:\")\n",
    "print(f\"Shape: {tips.shape}\")\n",
    "print(f\"\\nColumns: {list(tips.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the data\n",
    "print(\"üìä Dataset Statistics:\")\n",
    "print(tips.describe())\n",
    "\n",
    "print(\"\\nüîç Data Types:\")\n",
    "print(tips.dtypes)\n",
    "\n",
    "print(\"\\n‚ùì Missing Values:\")\n",
    "print(tips.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the target variable and key relationships\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Tip distribution\n",
    "axes[0,0].hist(tips['tip'], bins=20, alpha=0.7, color='skyblue')\n",
    "axes[0,0].set_title('Distribution of Tips')\n",
    "axes[0,0].set_xlabel('Tip Amount ($)')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "\n",
    "# Tip vs Total Bill\n",
    "axes[0,1].scatter(tips['total_bill'], tips['tip'], alpha=0.6, color='coral')\n",
    "axes[0,1].set_title('Tips vs Total Bill')\n",
    "axes[0,1].set_xlabel('Total Bill ($)')\n",
    "axes[0,1].set_ylabel('Tip ($)')\n",
    "\n",
    "# Tips by day\n",
    "sns.boxplot(data=tips, x='day', y='tip', ax=axes[1,0])\n",
    "axes[1,0].set_title('Tips by Day of Week')\n",
    "axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Tips by party size\n",
    "tips_by_size = tips.groupby('size')['tip'].mean()\n",
    "axes[1,1].bar(tips_by_size.index, tips_by_size.values, color='lightgreen')\n",
    "axes[1,1].set_title('Average Tip by Party Size')\n",
    "axes[1,1].set_xlabel('Party Size')\n",
    "axes[1,1].set_ylabel('Average Tip ($)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare the Data\n",
    "\n",
    "Let's split our data into features (X) and target (y), then create train/test splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "# We'll predict tip amount based on all other features\n",
    "X = tips.drop('tip', axis=1)  # Features: everything except tip\n",
    "y = tips['tip']               # Target: tip amount\n",
    "\n",
    "print(\"üéØ Target variable (what we're predicting):\")\n",
    "print(f\"Tip amount - Mean: ${y.mean():.2f}, Std: ${y.std():.2f}\")\n",
    "\n",
    "print(\"\\nüîß Features (what we're using to predict):\")\n",
    "print(f\"Features: {list(X.columns)}\")\n",
    "print(f\"Shape: {X.shape}\")\n",
    "\n",
    "# Create train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Data Split:\")\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import SimpleMLR and Start Modeling!\n",
    "\n",
    "Now comes the fun part - let's import SimpleMLR and see how easy it is to build powerful machine learning models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SimpleMLR - all three algorithms with the same interface!\n",
    "try:\n",
    "    from simple_mlr import (\n",
    "        # Basic regressors - simple fit/predict interface\n",
    "        XGBRegressor, LGBMRegressor, GBMRegressor,\n",
    "        \n",
    "        # Auto-tuners - automatically find best parameters\n",
    "        xgb_auto, lgbm_auto, gbm_auto,\n",
    "        \n",
    "        # Convenience functions\n",
    "        xgb_regressor, lgbm_regressor, gbm_regressor\n",
    "    )\n",
    "    print(\"üöÄ SimpleMLR imported successfully!\")\n",
    "    print(\"Ready to build amazing models with just a few lines of code!\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    print(\"Make sure SimpleMLR is installed and in your Python path.\")\n",
    "    print(\"You can install it with: pip install -e .\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Method 1: Quick One-Line Models\n",
    "\n",
    "The fastest way to build models with SimpleMLR - just one line per algorithm!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üèÉ‚Äç‚ôÇÔ∏è Building Quick Models (One line each!)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# One-line model building - SimpleMLR handles everything!\n",
    "print(\"\\n1Ô∏è‚É£ XGBoost Model:\")\n",
    "xgb_model = xgb_regressor(X_train, y_train)\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ LightGBM Model:\")\n",
    "lgbm_model = lgbm_regressor(X_train, y_train)\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ Sklearn GBM Model:\")\n",
    "gbm_model = gbm_regressor(X_train, y_train)\n",
    "\n",
    "print(\"\\n‚úÖ All models trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Instant Model Analysis with quick_graph()\n",
    "\n",
    "SimpleMLR's `quick_graph()` method gives you instant insights into your model's performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä XGBoost Performance Analysis:\")\n",
    "xgb_model.quick_graph(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä LightGBM Performance Analysis:\")\n",
    "lgbm_model.quick_graph(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Sklearn GBM Performance Analysis:\")\n",
    "gbm_model.quick_graph(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Method 2: Class-Based Approach with Custom Settings\n",
    "\n",
    "For more control, you can use the class-based approach and customize parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéõÔ∏è Building Models with Custom Settings\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create models with custom parameters\n",
    "print(\"\\nüöÄ XGBoost with custom settings:\")\n",
    "xgb_custom = XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "xgb_custom.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n‚ö° LightGBM with custom settings:\")\n",
    "lgbm_custom = LGBMRegressor(\n",
    "    num_boost_round=200,\n",
    "    num_leaves=31,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "lgbm_custom.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nüõ°Ô∏è Sklearn GBM with custom settings:\")\n",
    "gbm_custom = GBMRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "gbm_custom.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n‚úÖ Custom models trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Method 3: Automatic Hyperparameter Optimization üéØ\n",
    "\n",
    "This is where SimpleMLR really shines! Automatic hyperparameter optimization with different strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ Automatic Hyperparameter Optimization\")\n",
    "print(\"=\" * 45)\n",
    "print(\"This will find the best parameters automatically!\")\n",
    "print(\"\\nüöÄ XGBoost Auto-Optimization (Fast Strategy):\")\n",
    "\n",
    "# Auto-tuned XGBoost with 'fast' strategy for quick results\n",
    "xgb_optimized = xgb_auto(\n",
    "    X_train, y_train,\n",
    "    strategy='fast',        # Quick optimization\n",
    "    n_trials=25,           # Number of parameter combinations to try\n",
    "    verbose=1              # Show progress\n",
    ")\n",
    "\n",
    "print(\"\\n‚ö° XGBoost optimization completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚ö° LightGBM Auto-Optimization (Fast Strategy):\")\n",
    "\n",
    "# Auto-tuned LightGBM\n",
    "lgbm_optimized = lgbm_auto(\n",
    "    X_train, y_train,\n",
    "    strategy='fast',\n",
    "    n_trials=25,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚ö° LightGBM optimization completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üõ°Ô∏è Sklearn GBM Auto-Optimization (Stable Strategy):\")\n",
    "\n",
    "# Auto-tuned GBM with 'stable' strategy for reliability\n",
    "gbm_optimized = gbm_auto(\n",
    "    X_train, y_train,\n",
    "    strategy='stable',      # Stable, reliable parameters\n",
    "    n_trials=25,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nüõ°Ô∏è Sklearn GBM optimization completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Comprehensive Model Analysis\n",
    "\n",
    "Let's use SimpleMLR's advanced `plot_analysis()` method for detailed model insights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìà Comprehensive XGBoost Analysis:\")\n",
    "_, xgb_metrics = xgb_optimized.plot_analysis(\n",
    "    X_test, y_test,\n",
    "    title=\"XGBoost Optimized Model - Tips Prediction\",\n",
    "    style='modern'\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä XGBoost Detailed Metrics:\")\n",
    "for metric, value in xgb_metrics.items():\n",
    "    if isinstance(value, (int, float)):\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìà Comprehensive LightGBM Analysis:\")\n",
    "_, lgbm_metrics = lgbm_optimized.plot_analysis(\n",
    "    X_test, y_test,\n",
    "    title=\"LightGBM Optimized Model - Tips Prediction\",\n",
    "    style='modern'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìà Comprehensive Sklearn GBM Analysis:\")\n",
    "_, gbm_metrics = gbm_optimized.plot_analysis(\n",
    "    X_test, y_test,\n",
    "    title=\"Sklearn GBM Optimized Model - Tips Prediction\",\n",
    "    style='modern'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Comparison and Performance Summary\n",
    "\n",
    "Let's compare all our models to see which performs best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from all optimized models\n",
    "models = {\n",
    "    'XGBoost (Optimized)': xgb_optimized,\n",
    "    'LightGBM (Optimized)': lgbm_optimized,\n",
    "    'Sklearn GBM (Optimized)': gbm_optimized\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Get predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'R¬≤ Score': r2,\n",
    "        'RMSE': rmse,\n",
    "        'MAE': mae\n",
    "    })\n",
    "\n",
    "# Create comparison DataFrame\n",
    "comparison_df = pd.DataFrame(results)\n",
    "comparison_df = comparison_df.round(4)\n",
    "\n",
    "print(\"üèÜ Model Performance Comparison:\")\n",
    "print(\"=\" * 40)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Find best model\n",
    "best_model_idx = comparison_df['R¬≤ Score'].idxmax()\n",
    "best_model_name = comparison_df.loc[best_model_idx, 'Model']\n",
    "best_r2 = comparison_df.loc[best_model_idx, 'R¬≤ Score']\n",
    "\n",
    "print(f\"\\nü•á Best Model: {best_model_name}\")\n",
    "print(f\"   R¬≤ Score: {best_r2:.4f}\")\n",
    "print(f\"   (Higher R¬≤ is better - closer to 1.0 means better predictions)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Feature Importance Analysis\n",
    "\n",
    "Let's see which features are most important for predicting tips:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance from the best model\n",
    "best_model = models[best_model_name]\n",
    "\n",
    "if hasattr(best_model, 'get_feature_importance'):\n",
    "    print(f\"üîç Feature Importance Analysis - {best_model_name}:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    feature_importance = best_model.get_feature_importance()\n",
    "    print(feature_importance)\n",
    "    \n",
    "    # Create a feature importance plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_importance['feature'], feature_importance['importance'], color='skyblue')\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.title(f'Feature Importance - {best_model_name}')\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(feature_importance['importance']):\n",
    "        plt.text(v + 0.01, i, f'{v:.3f}', va='center')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nüí° Insights:\")\n",
    "    top_feature = feature_importance.iloc[0]['feature']\n",
    "    print(f\"   Most important feature: {top_feature}\")\n",
    "    print(f\"   This makes sense - {top_feature} likely has strong correlation with tip amount!\")\n",
    "else:\n",
    "    print(\"Feature importance not available for this model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Making Predictions on New Data\n",
    "\n",
    "Let's see how to use our trained model to make predictions on new restaurant visits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some example new data points\n",
    "new_data = pd.DataFrame({\n",
    "    'total_bill': [25.50, 45.20, 15.75, 62.30],\n",
    "    'sex': ['Male', 'Female', 'Male', 'Female'],\n",
    "    'smoker': ['No', 'Yes', 'No', 'No'],\n",
    "    'day': ['Sat', 'Sun', 'Fri', 'Sat'],\n",
    "    'time': ['Dinner', 'Dinner', 'Lunch', 'Dinner'],\n",
    "    'size': [2, 4, 1, 3]\n",
    "})\n",
    "\n",
    "print(\"üçΩÔ∏è New Restaurant Visits to Predict:\")\n",
    "print(new_data)\n",
    "\n",
    "# Make predictions\n",
    "predictions = best_model.predict(new_data)\n",
    "\n",
    "print(f\"\\nüí∞ Predicted Tips using {best_model_name}:\")\n",
    "print(\"=\" * 40)\n",
    "for i, (_, row) in enumerate(new_data.iterrows()):\n",
    "    tip_pred = predictions[i]\n",
    "    tip_percent = (tip_pred / row['total_bill']) * 100\n",
    "    print(f\"Visit {i+1}: Bill=${row['total_bill']:.2f} ‚Üí Predicted Tip=${tip_pred:.2f} ({tip_percent:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüìä Summary:\")\n",
    "print(f\"Average predicted tip: ${np.mean(predictions):.2f}\")\n",
    "print(f\"Range: ${np.min(predictions):.2f} - ${np.max(predictions):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Advanced Features and Tips\n",
    "\n",
    "Here are some advanced SimpleMLR features you can explore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Advanced SimpleMLR Features:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£ GPU Acceleration (if available):\")\n",
    "print(\"   xgb_auto(X, y, use_gpu=True)\")\n",
    "print(\"   lgbm_auto(X, y, use_gpu=True)\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ Different Optimization Strategies:\")\n",
    "print(\"   - 'fast': Quick optimization for experimentation\")\n",
    "print(\"   - 'stable': Reliable settings for production\")\n",
    "print(\"   - 'aggressive': Maximum performance, more exploration\")\n",
    "print(\"   - 'balanced': Good all-around choice\")\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ Parameter Override Examples:\")\n",
    "print(\"   xgb_auto(X, y, strategy='fast', override_params={\")\n",
    "print(\"       'max_depth': 6,              # Fix max_depth to 6\")\n",
    "print(\"       'learning_rate': (0.05, 0.2) # Custom range\")\n",
    "print(\"   })\")\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£ Validation Split (faster than cross-validation):\")\n",
    "print(\"   xgb_auto(X, y, validation_split=0.2)\")\n",
    "\n",
    "print(\"\\n5Ô∏è‚É£ More Trials for Better Results:\")\n",
    "print(\"   xgb_auto(X, y, n_trials=100)  # More exploration\")\n",
    "\n",
    "print(\"\\n6Ô∏è‚É£ Save Plots:\")\n",
    "print(\"   model.plot_analysis(X, y, save_path='analysis.png')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Congratulations!\n",
    "\n",
    "You've completed the SimpleMLR tutorial! Here's what you've learned:\n",
    "\n",
    "### ‚úÖ What You Accomplished:\n",
    "1. **Data Loading & Exploration** - Used Seaborn's tips dataset\n",
    "2. **Quick Model Building** - One-line models with three algorithms\n",
    "3. **Automatic Optimization** - Found best parameters automatically\n",
    "4. **Beautiful Visualizations** - Comprehensive model analysis\n",
    "5. **Model Comparison** - Compared XGBoost, LightGBM, and sklearn GBM\n",
    "6. **Feature Importance** - Understood which features matter most\n",
    "7. **Real Predictions** - Made predictions on new data\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "- Try SimpleMLR on your own datasets\n",
    "- Experiment with different strategies (`'aggressive'`, `'competition'`)\n",
    "- Use GPU acceleration for larger datasets\n",
    "- Explore parameter overrides for fine-tuning\n",
    "- Save your best models for production use\n",
    "\n",
    "### üìö Key Takeaways:\n",
    "- **SimpleMLR makes machine learning accessible** - complex algorithms with simple interfaces\n",
    "- **Consistent API across algorithms** - learn once, use everywhere\n",
    "- **Automatic optimization saves time** - no need to manually tune parameters\n",
    "- **Beautiful visualizations** - understand your models instantly\n",
    "- **Production ready** - from prototype to deployment seamlessly\n",
    "\n",
    "Happy modeling! üéØ‚ú®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"üéØ SimpleMLR Tutorial Complete! üéØ\")\n",
    "print(\"=\" * 35)\n",
    "print(f\"üìä Dataset: {tips.shape[0]} restaurant visits analyzed\")\n",
    "print(f\"ü§ñ Models trained: 3 different algorithms\")\n",
    "print(f\"üèÜ Best model: {best_model_name} (R¬≤ = {best_r2:.4f})\")\n",
    "print(f\"‚ö° Total predictions made: {len(predictions)} new visits\")\n",
    "print(\"\")\n",
    "print(\"üöÄ Ready to use SimpleMLR on your own data!\")\n",
    "print(\"üìñ Check the documentation for more advanced features\")\n",
    "print(\"üí° Happy machine learning!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}